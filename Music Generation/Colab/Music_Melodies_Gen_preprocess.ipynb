{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music_Melodies_Gen_preprocess.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1AbX42erZrhrz2tOqlBMCYdWpxf87LR8r",
      "authorship_tag": "ABX9TyOxwTg0sj/aMXbV7GoPKbMc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ki6an/Machine_Learning_Projects/blob/master/Music%20Generation/Colab/Music_Melodies_Gen_preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBRNHeT9eXMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "from music21 import converter, stream, key, interval, note\n",
        "import music21\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        " \n",
        " \n",
        "KERN_DATASET_PATH = '/content/drive/My Drive/Machine Learning /data/erk'\n",
        "SAVE_DIR = \"dataset\"\n",
        "SINGLE_FILE_DATASET = \"file_dataset\"\n",
        "MAPPING_PATH = \"mapping.json\"\n",
        "SEQUENCE_LENGTH = 64\n",
        " \n",
        "ACCEPTABLE_DURATIONS = [\n",
        "    0.25,\n",
        "    0.5,\n",
        "    0.75,\n",
        "    1.0,\n",
        "    1.5,\n",
        "    2,\n",
        "    3,\n",
        "    4\n",
        "]\n",
        " \n",
        " \n",
        "def has_acceptable_duration(song, acceptable_durations):\n",
        "    for note in song.flat.notesAndRests:\n",
        "        if note.duration.quarterLength not in acceptable_durations:\n",
        "            return False\n",
        "    return True\n",
        " \n",
        " \n",
        "def load_songs_in_kern(dataset_path):\n",
        "    pass\n",
        "    songs = []\n",
        " \n",
        "    for path, subdirs, files in os.walk(dataset_path):\n",
        "        for file in files:\n",
        " \n",
        "            # consider only kern files\n",
        "            if file[-3:] == 'krn':\n",
        "                song = converter.parse(os.path.join(path, file))\n",
        "                songs.append(song)\n",
        "    return songs\n",
        " \n",
        " \n",
        "def transpose(song):\n",
        "    # get the key from the song\n",
        "    parts = song.getElementsByClass(stream.Part)\n",
        "    measures_part0 = parts[0].getElementsByClass(stream.Measure)\n",
        "    key_x = measures_part0[0][4]\n",
        " \n",
        "    # estimate key using music21\n",
        "    if not isinstance(key_x, key.Key):\n",
        "        key_x = song.analyze('key')\n",
        " \n",
        "    print(key_x)\n",
        " \n",
        "    # get interval for transposition, Eg: Bmaj to Cmaj\n",
        "    if key_x.mode == 'major':\n",
        "        interval_x = music21.interval.Interval(key_x.tonic, music21.pitch.Pitch('C'))\n",
        "    elif key_x.mode == 'minor':\n",
        "        interval_x = music21.interval.Interval(key_x.tonic, music21.pitch.Pitch('A'))\n",
        " \n",
        "    # transpose song by calculated interval\n",
        "    transposed_song = song.transpose(interval_x)\n",
        " \n",
        "    return transposed_song\n",
        " \n",
        " \n",
        "def encode_song(song, time_step=0.25):\n",
        "    \"\"\"Converts a score into a time-series-like music representation. Each item in the encoded list represents 'min_duration'\n",
        "    quarter lengths. The symbols used at each step are: integers for MIDI notes, 'r' for representing a rest, and '_'\n",
        "    for representing notes/rests that are carried over into a new time step. Here's a sample encoding:\n",
        "        [\"r\", \"_\", \"60\", \"_\", \"_\", \"_\", \"72\" \"_\"]\n",
        "    :param song (m21 stream): Piece to encode\n",
        "    :param time_step (float): Duration of each time step in quarter length\n",
        "    :return:\n",
        "    \"\"\"\n",
        " \n",
        "    encoded_song = []\n",
        " \n",
        "    for event in song.flat.notesAndRests:\n",
        " \n",
        "        # handle notes\n",
        "        if isinstance(event, note.Note):\n",
        "            symbol = event.pitch.midi # 60\n",
        "        # handle rests\n",
        "        elif isinstance(event, note.Rest):\n",
        "            symbol = \"r\"\n",
        " \n",
        "        # convert the note/rest into time series notation\n",
        "        steps = int(event.duration.quarterLength / time_step)\n",
        "        for step in range(steps):\n",
        " \n",
        "            # if it's the first time we see a note/rest, let's encode it. Otherwise, it means we're carrying the same\n",
        "            # symbol in a new time step\n",
        "            if step == 0:\n",
        "                encoded_song.append(symbol)\n",
        "            else:\n",
        "                encoded_song.append(\"_\")\n",
        " \n",
        "    # cast encoded song to str\n",
        "    encoded_song = \" \".join(map(str, encoded_song))\n",
        " \n",
        "    return encoded_song\n",
        " \n",
        " \n",
        "def pre_process(dataset_path):\n",
        " \n",
        "    # load folk songs\n",
        "    print(\"Loading songs...\")\n",
        "    songs = load_songs_in_kern(dataset_path)\n",
        "    print(f\"Loaded {len(songs)} songs.\")\n",
        " \n",
        "    for i, song in enumerate(songs):\n",
        " \n",
        "        # filter out songs that have non-acceptable durations\n",
        "        if not has_acceptable_duration(song, ACCEPTABLE_DURATIONS):\n",
        "            continue\n",
        " \n",
        "        # transpose songs to Cmaj/Amin\n",
        "        song = transpose(song)\n",
        " \n",
        "        # encode songs with music time series representation\n",
        "        encoded_song = encode_song(song)\n",
        " \n",
        "        # save songs to text file\n",
        "        save_path = os.path.join(SAVE_DIR, str(i))\n",
        "        with open(save_path, \"w\") as fp:\n",
        "            fp.write(encoded_song)\n",
        " \n",
        " \n",
        "def load(file_path):\n",
        "    with open(file_path, \"r\") as fp:\n",
        "        song = fp.read()\n",
        "    return song\n",
        " \n",
        " \n",
        "def create_single_file_dataset(dataset_path, file_dataset_path, sequence_length):\n",
        "    \"\"\"Generates a file collating all the encoded songs and adding new piece delimiters.\n",
        "    :param dataset_path (str): Path to folder containing the encoded songs\n",
        "    :param file_dataset_path (str): Path to file for saving songs in single file\n",
        "    :param sequence_length (int): # of time steps to be considered for training\n",
        "    :return songs (str): String containing all songs in dataset + delimiters\n",
        "    \"\"\"\n",
        " \n",
        "    new_song_delimiter = \"/ \" * sequence_length\n",
        "    songs = \"\"\n",
        " \n",
        "    # load encoded songs and add delimiters\n",
        "    for path, _, files in os.walk(dataset_path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(path, file)\n",
        "            song = load(file_path)\n",
        "            songs = songs + song + \" \" + new_song_delimiter\n",
        " \n",
        "    # remove empty space from last character of string\n",
        "    songs = songs[:-1]\n",
        " \n",
        "    # save string that contains all the dataset\n",
        "    with open(file_dataset_path, \"w\") as fp:\n",
        "        fp.write(songs)\n",
        " \n",
        "    return songs\n",
        " \n",
        " \n",
        "def create_mapping(songs, mapping_path):\n",
        "    \"\"\"Creates a json file that maps the symbols in the song dataset onto integers\n",
        "    :param songs (str): String with all songs\n",
        "    :param mapping_path (str): Path where to save mapping\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    mappings = {}\n",
        " \n",
        "    # identify the vocabulary\n",
        "    songs = songs.split()\n",
        "    vocabulary = list(set(songs))\n",
        " \n",
        "    # create mappings\n",
        "    for i, symbol in enumerate(vocabulary):\n",
        "        mappings[symbol] = i\n",
        " \n",
        "    # save voabulary to a json file\n",
        "    with open(mapping_path, \"w\") as fp:\n",
        "        json.dump(mappings, fp, indent=4)\n",
        " \n",
        "def convert_songs_to_int(songs):\n",
        "    int_songs = []\n",
        " \n",
        "    # load mappings\n",
        "    with open(MAPPING_PATH, \"r\") as fp:\n",
        "        mappings = json.load(fp)\n",
        " \n",
        "    # transform songs string to list\n",
        "    songs = songs.split()\n",
        " \n",
        "    # map songs to int\n",
        "    for symbol in songs:\n",
        "        int_songs.append(mappings[symbol])\n",
        " \n",
        "    return int_songs\n",
        " \n",
        " \n",
        "def generate_training_sequences(sequence_length):\n",
        "    \"\"\"Create input and output data samples for training. Each sample is a sequence.\n",
        "    :param sequence_length (int): Length of each sequence. With a quantisation at 16th notes, 64 notes equates to 4 bars\n",
        "    :return inputs (ndarray): Training inputs\n",
        "    :return targets (ndarray): Training targets\n",
        "    \"\"\"\n",
        " \n",
        "    # load songs and map them to int\n",
        "    songs = load(SINGLE_FILE_DATASET)\n",
        "    int_songs = convert_songs_to_int(songs)\n",
        " \n",
        "    inputs = []\n",
        "    targets = []\n",
        " \n",
        "    # generate the training sequences\n",
        "    num_sequences = len(int_songs) - sequence_length\n",
        "    for i in range(num_sequences):\n",
        "        inputs.append(int_songs[i:i+sequence_length])\n",
        "        targets.append(int_songs[i+sequence_length])\n",
        " \n",
        "    # one-hot encode the sequences\n",
        "    vocabulary_size = len(set(int_songs))\n",
        "    # inputs size: (# of sequences, sequence length, vocabulary size)\n",
        "    inputs = keras.utils.to_categorical(inputs, num_classes=vocabulary_size)\n",
        "    targets = np.array(targets)\n",
        " \n",
        "    return inputs, targets\n",
        " \n",
        " \n",
        "def main():\n",
        "    pre_process(KERN_DATASET_PATH)\n",
        "    songs = create_single_file_dataset(SAVE_DIR, SINGLE_FILE_DATASET, SEQUENCE_LENGTH)\n",
        "    create_mapping(songs, MAPPING_PATH)\n",
        "    inputs, targets = generate_training_sequences(SEQUENCE_LENGTH)\n",
        "    # for debugging   a = 1\n",
        " \n",
        " \n",
        "main()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEaET6NaxAi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY5_SsB-3m1D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3acf6517-3a90-4e6a-b50a-28388904d25c"
      },
      "source": [
        "import tensorflow.keras as keras\n",
        "\n",
        "OUTPUT_UNITS = 38\n",
        "NUM_UNITS = [256]\n",
        "LOSS = \"sparse_categorical_crossentropy\"\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 64\n",
        "SAVE_MODEL_PATH = \"model.h5\"\n",
        "\n",
        "\n",
        "def build_model(output_units, num_units, loss, learning_rate):\n",
        "    \"\"\"Builds and compiles model\n",
        "    :param output_units (int): Num output units\n",
        "    :param num_units (list of int): Num of units in hidden layers\n",
        "    :param loss (str): Type of loss function to use\n",
        "    :param learning_rate (float): Learning rate to apply\n",
        "    :return model (tf model): Where the magic happens :D\n",
        "    \"\"\"\n",
        "\n",
        "    # create the model architecture\n",
        "    input = keras.layers.Input(shape=(None, output_units))\n",
        "    x = keras.layers.LSTM(num_units[0])(input)\n",
        "    x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "    output = keras.layers.Dense(output_units, activation=\"softmax\")(x)\n",
        "\n",
        "    model = keras.Model(input, output)\n",
        "\n",
        "    # compile model\n",
        "    model.compile(loss=loss,\n",
        "                  optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def train(output_units=OUTPUT_UNITS, num_units=NUM_UNITS, loss=LOSS, learning_rate=LEARNING_RATE):\n",
        "    \"\"\"Train and save TF model.\n",
        "    :param output_units (int): Num output units\n",
        "    :param num_units (list of int): Num of units in hidden layers\n",
        "    :param loss (str): Type of loss function to use\n",
        "    :param learning_rate (float): Learning rate to apply\n",
        "    \"\"\"\n",
        "\n",
        "    # generate the training sequences\n",
        "    inputs, targets = generate_training_sequences(SEQUENCE_LENGTH)\n",
        "\n",
        "    # build the network\n",
        "    model = build_model(output_units, num_units, loss, learning_rate)\n",
        "\n",
        "    # train the model\n",
        "    model.fit(inputs, targets, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
        "\n",
        "    # save the model\n",
        "    model.save(SAVE_MODEL_PATH)\n",
        "\n",
        "train()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None, 38)]        0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 256)               302080    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 38)                9766      \n",
            "=================================================================\n",
            "Total params: 311,846\n",
            "Trainable params: 311,846\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.6922 - accuracy: 0.7870\n",
            "Epoch 2/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.5788 - accuracy: 0.8130\n",
            "Epoch 3/50\n",
            "5660/5660 [==============================] - 113s 20ms/step - loss: 0.5458 - accuracy: 0.8242\n",
            "Epoch 4/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.5240 - accuracy: 0.8305\n",
            "Epoch 5/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.5054 - accuracy: 0.8355\n",
            "Epoch 6/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.4977 - accuracy: 0.8381\n",
            "Epoch 7/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.4759 - accuracy: 0.8437\n",
            "Epoch 8/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.4583 - accuracy: 0.8495\n",
            "Epoch 9/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.4427 - accuracy: 0.8546\n",
            "Epoch 10/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.4275 - accuracy: 0.8586\n",
            "Epoch 11/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.4167 - accuracy: 0.8624\n",
            "Epoch 12/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.4035 - accuracy: 0.8664\n",
            "Epoch 13/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.3911 - accuracy: 0.8699\n",
            "Epoch 14/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.3820 - accuracy: 0.8734\n",
            "Epoch 15/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.3699 - accuracy: 0.8768\n",
            "Epoch 16/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.3646 - accuracy: 0.8778\n",
            "Epoch 17/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.3648 - accuracy: 0.8780\n",
            "Epoch 18/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.3540 - accuracy: 0.8815\n",
            "Epoch 19/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.3464 - accuracy: 0.8840\n",
            "Epoch 20/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.3425 - accuracy: 0.8854\n",
            "Epoch 21/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.3404 - accuracy: 0.8856\n",
            "Epoch 22/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.3124 - accuracy: 0.8952\n",
            "Epoch 23/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.3173 - accuracy: 0.8934\n",
            "Epoch 24/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.3245 - accuracy: 0.8904\n",
            "Epoch 25/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.3159 - accuracy: 0.8935\n",
            "Epoch 26/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.3138 - accuracy: 0.8942\n",
            "Epoch 27/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.3111 - accuracy: 0.8950\n",
            "Epoch 28/50\n",
            "5660/5660 [==============================] - 113s 20ms/step - loss: 0.3226 - accuracy: 0.8916\n",
            "Epoch 29/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.3019 - accuracy: 0.8971\n",
            "Epoch 30/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.3029 - accuracy: 0.8973\n",
            "Epoch 31/50\n",
            "5660/5660 [==============================] - 113s 20ms/step - loss: 0.2942 - accuracy: 0.9003\n",
            "Epoch 32/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.2916 - accuracy: 0.9012\n",
            "Epoch 33/50\n",
            "5660/5660 [==============================] - 114s 20ms/step - loss: 0.2895 - accuracy: 0.9015\n",
            "Epoch 34/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.2847 - accuracy: 0.9033\n",
            "Epoch 35/50\n",
            "5660/5660 [==============================] - 113s 20ms/step - loss: 0.2847 - accuracy: 0.9032\n",
            "Epoch 36/50\n",
            "5660/5660 [==============================] - 113s 20ms/step - loss: 0.2780 - accuracy: 0.9054\n",
            "Epoch 37/50\n",
            "5660/5660 [==============================] - 111s 20ms/step - loss: 0.2786 - accuracy: 0.9053\n",
            "Epoch 38/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.2771 - accuracy: 0.9056\n",
            "Epoch 39/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.2719 - accuracy: 0.9072\n",
            "Epoch 40/50\n",
            "5660/5660 [==============================] - 111s 20ms/step - loss: 0.2714 - accuracy: 0.9076\n",
            "Epoch 41/50\n",
            "5660/5660 [==============================] - 111s 20ms/step - loss: 0.2629 - accuracy: 0.9101\n",
            "Epoch 42/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.2591 - accuracy: 0.9112\n",
            "Epoch 43/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.2595 - accuracy: 0.9114\n",
            "Epoch 44/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.2552 - accuracy: 0.9126\n",
            "Epoch 45/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.2562 - accuracy: 0.9127\n",
            "Epoch 46/50\n",
            "5660/5660 [==============================] - 111s 20ms/step - loss: 0.2530 - accuracy: 0.9135\n",
            "Epoch 47/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.2530 - accuracy: 0.9138\n",
            "Epoch 48/50\n",
            "5660/5660 [==============================] - 111s 20ms/step - loss: 0.2482 - accuracy: 0.9151\n",
            "Epoch 49/50\n",
            "5660/5660 [==============================] - 111s 20ms/step - loss: 0.2506 - accuracy: 0.9143\n",
            "Epoch 50/50\n",
            "5660/5660 [==============================] - 112s 20ms/step - loss: 0.2460 - accuracy: 0.9158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi8ChBWcRDTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crepxwxHRDrD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "fdb7c683-4a5e-4be7-f7d1-f6ff71e4c45b"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow.keras as keras\n",
        "import music21 as m21\n",
        "# from preprocess import SEQUENCE_LENGTH, MAPPING_PATH\n",
        "\n",
        "class MelodyGenerator:\n",
        "    \"\"\"A class that wraps the LSTM model and offers utilities to generate melodies.\"\"\"\n",
        "\n",
        "    def __init__(self, model_path=\"model.h5\"):\n",
        "        \"\"\"Constructor that initialises TensorFlow model\"\"\"\n",
        "\n",
        "        self.model_path = model_path\n",
        "        self.model = keras.models.load_model(model_path)\n",
        "\n",
        "        with open(MAPPING_PATH, \"r\") as fp:\n",
        "            self._mappings = json.load(fp)\n",
        "\n",
        "        self._start_symbols = [\"/\"] * SEQUENCE_LENGTH\n",
        "\n",
        "\n",
        "    def generate_melody(self, seed, num_steps, max_sequence_length, temperature):\n",
        "        \"\"\"Generates a melody using the DL model and returns a midi file.\n",
        "        :param seed (str): Melody seed with the notation used to encode the dataset\n",
        "        :param num_steps (int): Number of steps to be generated\n",
        "        :param max_sequence_len (int): Max number of steps in seed to be considered for generation\n",
        "        :param temperature (float): Float in interval [0, 1]. Numbers closer to 0 make the model more deterministic.\n",
        "            A number closer to 1 makes the generation more unpredictable.\n",
        "        :return melody (list of str): List with symbols representing a melody\n",
        "        \"\"\"\n",
        "\n",
        "        # create seed with start symbols\n",
        "        seed = seed.split()\n",
        "        melody = seed\n",
        "        seed = self._start_symbols + seed\n",
        "\n",
        "        # map seed to int\n",
        "        seed = [self._mappings[symbol] for symbol in seed]\n",
        "\n",
        "        for _ in range(num_steps):\n",
        "\n",
        "            # limit the seed to max_sequence_length\n",
        "            seed = seed[-max_sequence_length:]\n",
        "\n",
        "            # one-hot encode the seed\n",
        "            onehot_seed = keras.utils.to_categorical(seed, num_classes=len(self._mappings))\n",
        "            # (1, max_sequence_length, num of symbols in the vocabulary)\n",
        "            onehot_seed = onehot_seed[np.newaxis, ...]\n",
        "\n",
        "            # make a prediction\n",
        "            probabilities = self.model.predict(onehot_seed)[0]\n",
        "            # [0.1, 0.2, 0.1, 0.6] -> 1\n",
        "            output_int = self._sample_with_temperature(probabilities, temperature)\n",
        "\n",
        "            # update seed\n",
        "            seed.append(output_int)\n",
        "\n",
        "            # map int to our encoding\n",
        "            output_symbol = [k for k, v in self._mappings.items() if v == output_int][0]\n",
        "\n",
        "            # check whether we're at the end of a melody\n",
        "            if output_symbol == \"/\":\n",
        "                break\n",
        "\n",
        "            # update melody\n",
        "            melody.append(output_symbol)\n",
        "\n",
        "        return melody\n",
        "\n",
        "\n",
        "    def _sample_with_temperature(self, probabilites, temperature):\n",
        "        \"\"\"Samples an index from a probability array reapplying softmax using temperature\n",
        "        :param predictions (nd.array): Array containing probabilities for each of the possible outputs.\n",
        "        :param temperature (float): Float in interval [0, 1]. Numbers closer to 0 make the model more deterministic.\n",
        "            A number closer to 1 makes the generation more unpredictable.\n",
        "        :return index (int): Selected output symbol\n",
        "        \"\"\"\n",
        "        predictions = np.log(probabilites) / temperature\n",
        "        probabilites = np.exp(predictions) / np.sum(np.exp(predictions))\n",
        "\n",
        "        choices = range(len(probabilites)) # [0, 1, 2, 3]\n",
        "        index = np.random.choice(choices, p=probabilites)\n",
        "\n",
        "        return index\n",
        "\n",
        "\n",
        "    def save_melody(self, melody, step_duration=0.25, format=\"midi\", file_name=\"mel.mid\"):\n",
        "        \"\"\"Converts a melody into a MIDI file\n",
        "        :param melody (list of str):\n",
        "        :param min_duration (float): Duration of each time step in quarter length\n",
        "        :param file_name (str): Name of midi file\n",
        "        :return:\n",
        "        \"\"\"\n",
        "\n",
        "        # create a music21 stream\n",
        "        stream = m21.stream.Stream()\n",
        "\n",
        "        start_symbol = None\n",
        "        step_counter = 1\n",
        "\n",
        "        # parse all the symbols in the melody and create note/rest objects\n",
        "        for i, symbol in enumerate(melody):\n",
        "\n",
        "            # handle case in which we have a note/rest\n",
        "            if symbol != \"_\" or i + 1 == len(melody):\n",
        "\n",
        "                # ensure we're dealing with note/rest beyond the first one\n",
        "                if start_symbol is not None:\n",
        "\n",
        "                    quarter_length_duration = step_duration * step_counter # 0.25 * 4 = 1\n",
        "\n",
        "                    # handle rest\n",
        "                    if start_symbol == \"r\":\n",
        "                        m21_event = m21.note.Rest(quarterLength=quarter_length_duration)\n",
        "\n",
        "                    # handle note\n",
        "                    else:\n",
        "                        m21_event = m21.note.Note(int(start_symbol), quarterLength=quarter_length_duration)\n",
        "\n",
        "                    stream.append(m21_event)\n",
        "\n",
        "                    # reset the step counter\n",
        "                    step_counter = 1\n",
        "\n",
        "                start_symbol = symbol\n",
        "\n",
        "            # handle case in which we have a prolongation sign \"_\"\n",
        "            else:\n",
        "                step_counter += 1\n",
        "\n",
        "        # write the m21 stream to a midi file\n",
        "        stream.write(format, file_name)\n",
        "\n",
        "\n",
        "\n",
        "mg = MelodyGenerator()\n",
        "seed = \"67 _ 67 _ 67 _ _ 65 64 _ 64 _ 64 _ _\"\n",
        "seed2 = \"67 _ _ _ _ _ 65 _ 64 _ 62 _ 60 _ _ _\"\n",
        "melody = mg.generate_melody(seed, 500, SEQUENCE_LENGTH, 0.3)\n",
        "print(melody)\n",
        "mg.save_melody(melody)\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['67', '_', '67', '_', '67', '_', '_', '65', '64', '_', '64', '_', '64', '_', '_', '_', '67', '_', '_', '_', '64', '_', '_', '_', '62', '_', '_', '_', '60', '_', '_', '_', 'r', '_', '_', '_', '67', '_', '_', '_', '64', '_', '_', '_', '67', '_', '_', '_', '69', '_', '67', '_', '65', '_', '64', '_', '65', '_', '_', '_', '65', '_', '_', '_', '67', '_', '65', '_', '64', '_', '_', '_', '64', '_', '_', '_', '67', '_', '64', '_', '64', '_', '62', '_', '62', '_', '_', '_', '69', '_', '_', '_', '67', '_', '_', '_', '64', '_', '_', '_', '62', '_', '_', '_', '60', '_', '_', '_', '_', '_', '_', '_']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkZ4U0ga3nOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6D3Z7VpkG2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}